import torch
print(f"PyTorch version: {torch.__version__}")
if not torch.cuda.is_available():
    print("ðŸš¨ FEHLER: CUDA ist immer noch nicht verfÃ¼gbar!")
else:
    print("âœ… CUDA ist verfÃ¼gbar!")
    print(f"Installierte CUDA-Version von PyTorch: {torch.version.cuda}")
    print(f"GPU-Modell: {torch.cuda.get_device_name(0)}")
    major, minor = torch.cuda.get_device_capability(0)
    print(f"Compute Capability: sm_{major}{minor}")
