{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef766e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape der skalierten, rebinned Daten: (1000, 130)\n",
      "Anzahl der Zeitpunkte pro Serie (nach Rebinning): 130\n",
      "\n",
      "✨ Lorenz-Zeitreihen im Long-Format erstellt!\n",
      "\n",
      "📦 Erste 5 Zeilen des Long-Format DataFrames:\n",
      "           date      data       cols\n",
      "0  1.577837e+18  5.362418  Channel_0\n",
      "1  1.577837e+18  1.933693  Channel_0\n",
      "2  1.577837e+18  2.452592  Channel_0\n",
      "3  1.577837e+18  3.211117  Channel_0\n",
      "4  1.577837e+18  3.911674  Channel_0\n",
      "\n",
      "📊 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130000 entries, 0 to 129999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    130000 non-null  float64\n",
      " 1   data    130000 non-null  float64\n",
      " 2   cols    130000 non-null  object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 3.0+ MB\n",
      "\n",
      "📏 Gesamt-DataFrame Shape: (130000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import odeint\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# --- 1. Lorenz System Definition (aus dem Originalcode) ---\n",
    "rho = 45.92\n",
    "sigma = 16.0\n",
    "beta = 8.0 / 2.0\n",
    "\n",
    "def lorenz_equation(state, t):\n",
    "    x, y, z = state\n",
    "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z\n",
    "\n",
    "def lorenz(t, init):\n",
    "    return odeint(lorenz_equation, init, t)\n",
    "\n",
    "# --- 2. Datengenerierung (aus dem Originalcode) ---\n",
    "def generate_data(t, samples=1, mixtures=[], inits=[], noise=0.6):\n",
    "    assert(len(mixtures) == len(inits))\n",
    "    candidates = []\n",
    "    data = np.zeros((samples, t.shape[0], 1))\n",
    "    candidate_index = np.zeros((samples), dtype=int)\n",
    "\n",
    "    for init in inits:\n",
    "        candidates.append(lorenz(t, init)[:, 0:1].tolist())\n",
    "    candidates = np.array(candidates)\n",
    "\n",
    "    randoms = np.random.uniform(size=samples)\n",
    "    for i in range(len(mixtures)):\n",
    "        if i == 0:\n",
    "            indices = np.where((randoms >= 0) & (randoms < mixtures[i]))[0]\n",
    "        else:\n",
    "            indices = np.where((randoms >= mixtures[i-1]) & (randoms < mixtures[i]))[0]\n",
    "        for index in indices:\n",
    "            data[index] = candidates[i] + np.random.normal(loc=0.0, scale=noise, size=candidates[i].shape)\n",
    "            candidate_index[index] = i\n",
    "    return data, candidate_index, t\n",
    "\n",
    "# --- 3. Rebinning Funktion (aus dem Originalcode) ---\n",
    "def rebin(arr, new_shape):\n",
    "    shape = (new_shape[0], arr.shape[0] // new_shape[0],\n",
    "             new_shape[1], arr.shape[1] // new_shape[1],)\n",
    "    return arr.reshape(shape).mean(-1).mean(1)\n",
    "\n",
    "# --- 4. Parameter und Generierung der Rohdaten (entspricht In [6] - In [10] im Originalcode) ---\n",
    "\n",
    "t_full = np.arange(0.0, 26.0, 0.02) # Originale Zeitachse\n",
    "\n",
    "inits = [\n",
    "    [ 1.0, 1.0001         , 1.0 ],\n",
    "    [ 1.0, 1.000001       , 1.0 ],\n",
    "    [ 1.0, 1.00000001     , 1.0 ],\n",
    "    [ 1.0, 1.0000000001   , 1.0 ],\n",
    "    [ 1.0, 1.000000000001 , 1.0 ],\n",
    "]\n",
    "\n",
    "# Generiere Mischungsverhältnisse\n",
    "num_candidates = 5\n",
    "points = 1000 # Dies war die Basis für die Mischungsverhältnisse, nicht die Samples\n",
    "distr = np.clip(np.random.normal(loc=0.5, scale=0.2, size=points), a_min=0, a_max=1)\n",
    "mixtures, edges = np.histogram(distr, bins=num_candidates)\n",
    "mixtures = mixtures / points\n",
    "tmp = 0\n",
    "for i, mixture in enumerate(mixtures):\n",
    "    tmp += mixture\n",
    "    mixtures[i] = tmp\n",
    "\n",
    "# Daten generieren\n",
    "num_samples = 1000 # Für dieses Beispiel reduzieren wir die Anzahl der Samples, um es übersichtlicher zu halten\n",
    "                   # Im Originalcode waren es 100000, das würde sehr groß werden!\n",
    "data_raw, indices, t_generated = generate_data(t_full, samples=num_samples, mixtures=mixtures, inits=inits, noise=7.2)\n",
    "\n",
    "# Rebinning und Skalierung\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-10, 10))\n",
    "rebinned_data = rebin(data_raw[:, :, 0], (data_raw.shape[0], data_raw.shape[1] // 10))\n",
    "rebinned_time = t_full[::10] # Die neue Zeitachse nach dem Rebinning\n",
    "\n",
    "scaler.fit(rebinned_data)\n",
    "rebinned_data_scaled = scaler.transform(rebinned_data)\n",
    "# rebinned_data_scaled hat nun Shape (num_samples, num_rebinned_timepoints)\n",
    "# z.B. (1000, 130)\n",
    "\n",
    "print(f\"Shape der skalierten, rebinned Daten: {rebinned_data_scaled.shape}\")\n",
    "print(f\"Anzahl der Zeitpunkte pro Serie (nach Rebinning): {rebinned_data_scaled.shape[1]}\")\n",
    "\n",
    "# --- 5. Transformation ins Long-Format ---\n",
    "\n",
    "long_format_data = []\n",
    "# Generische Start-Unix-Zeit in Nanosekunden (z.B. 1. Januar 2020)\n",
    "start_unix_ns = pd.Timestamp('2020-01-01 00:00:00 UTC').value\n",
    "\n",
    "# Zeitintervall in Nanosekunden (entspricht dem Zeitabstand in rebinned_time)\n",
    "# rebinned_time.shape[1] = 130\n",
    "# t_full.shape[0] = 1300\n",
    "# t_full[0] = 0.0, t_full[1] = 0.02, ... t_full[1299] = 25.98\n",
    "# rebinned_time[0] = 0.0, rebinned_time[1] = 0.2, ... rebinned_time[129] = 25.8\n",
    "# Der Zeitabstand ist 0.2 Sekunden (t_full[::10])\n",
    "# 0.2 Sekunden in Nanosekunden: 0.2 * 1,000,000,000 = 200,000,000 ns\n",
    "time_step_ns = (rebinned_time[1] - rebinned_time[0]) * 1_000_000_000 \n",
    "\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Generiere Unix-Zeiten für diese Serie\n",
    "    # Jedes Sample hat die gleichen Zeitstempel relativ zum Start\n",
    "    current_series_times = np.array([start_unix_ns + j * time_step_ns for j in range(rebinned_data_scaled.shape[1])])\n",
    "    \n",
    "    # Extrahiere die Daten für das aktuelle Sample\n",
    "    series_data = rebinned_data_scaled[i] # Dies ist ein 1D-Array von 130 Werten\n",
    "\n",
    "    # Erstelle einen temporären DataFrame für diese eine Zeitreihe\n",
    "    df_temp = pd.DataFrame({\n",
    "        'date': current_series_times,\n",
    "        'data': series_data,\n",
    "        'cols': f'Channel_{i}' # Jedes Sample wird ein eigener \"Kanal\"\n",
    "    })\n",
    "    long_format_data.append(df_temp)\n",
    "\n",
    "# Verkette alle temporären DataFrames\n",
    "df_time_series_long = pd.concat(long_format_data, ignore_index=True)\n",
    "\n",
    "print(\"\\n✨ Lorenz-Zeitreihen im Long-Format erstellt!\")\n",
    "print(\"\\n📦 Erste 5 Zeilen des Long-Format DataFrames:\")\n",
    "print(df_time_series_long.head())\n",
    "\n",
    "print(\"\\n📊 DataFrame Info:\")\n",
    "df_time_series_long.info()\n",
    "\n",
    "print(f\"\\n📏 Gesamt-DataFrame Shape: {df_time_series_long.shape}\")\n",
    "\n",
    "# Optional: Speichern als CSV\n",
    "# df_time_series_long.to_csv(\"lorenz_time_series_long_format.csv\", index=False)\n",
    "# print(\"\\nDatei 'lorenz_time_series_long_format.csv' wurde gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60edc047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>5.362418</td>\n",
       "      <td>Channel_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>1.933693</td>\n",
       "      <td>Channel_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>2.452592</td>\n",
       "      <td>Channel_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>3.211117</td>\n",
       "      <td>Channel_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>3.911674</td>\n",
       "      <td>Channel_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129995</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>6.690909</td>\n",
       "      <td>Channel_999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129996</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>7.057986</td>\n",
       "      <td>Channel_999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129997</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>5.313935</td>\n",
       "      <td>Channel_999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129998</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>-4.841353</td>\n",
       "      <td>Channel_999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129999</th>\n",
       "      <td>1.577837e+18</td>\n",
       "      <td>7.369039</td>\n",
       "      <td>Channel_999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date      data         cols\n",
       "0       1.577837e+18  5.362418    Channel_0\n",
       "1       1.577837e+18  1.933693    Channel_0\n",
       "2       1.577837e+18  2.452592    Channel_0\n",
       "3       1.577837e+18  3.211117    Channel_0\n",
       "4       1.577837e+18  3.911674    Channel_0\n",
       "...              ...       ...          ...\n",
       "129995  1.577837e+18  6.690909  Channel_999\n",
       "129996  1.577837e+18  7.057986  Channel_999\n",
       "129997  1.577837e+18  5.313935  Channel_999\n",
       "129998  1.577837e+18 -4.841353  Channel_999\n",
       "129999  1.577837e+18  7.369039  Channel_999\n",
       "\n",
       "[130000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcbc8956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starte Generierung der Lorenz-Zeitreihen mit Numba-Optimierung...\n",
      "Generiere 5 Lorenz-Kandidaten (Länge: 1000000 Punkte)...\n",
      "  Simuliere Kandidat 1/5...\n",
      "  Simuliere Kandidat 2/5...\n",
      "  Simuliere Kandidat 3/5...\n",
      "  Simuliere Kandidat 4/5...\n",
      "  Simuliere Kandidat 5/5...\n",
      "  Kandidaten-Simulation beendet in 22.60 Sekunden.\n",
      "Mische und füge Rauschen hinzu für 10 Samples (Numba-optimiert)...\n",
      "  Mischen und Rauschen beendet in 1.77 Sekunden.\n",
      "Gesamte Rohdaten-Generierung beendet in 24.37 Sekunden.\n",
      "\n",
      "Rebinning der Daten mit Faktor 100 (Numba-optimiert)...\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<function mean at 0x106c02fc0>) found for signature:\n \n >>> mean(array(float64, 4d, C), axis=Literal[int](3))\n \nThere are 2 candidate implementations:\n\u001b[1m  - Of which 2 did not match due to:\n  Overload in function 'array_mean': File: numba/np/old_arraymath.py: Line 424.\n    With argument(s): '(array(float64, 4d, C), axis=int64)':\u001b[0m\n\u001b[1m   Rejected as the implementation raised a specific error:\n     TypingError: \u001b[1mgot an unexpected keyword argument 'axis'\u001b[0m\u001b[0m\n  raised from /opt/miniconda3/envs/ag/lib/python3.11/site-packages/numba/core/typing/templates.py:791\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<function mean at 0x106c02fc0>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /var/folders/bm/0j4cpchs2qx9r4_5l3k5pd5c0000gn/T/ipykernel_71226/3309363379.py (81)\n\u001b[0m\n\u001b[1m\nFile \"../../../var/folders/bm/0j4cpchs2qx9r4_5l3k5pd5c0000gn/T/ipykernel_71226/3309363379.py\", line 81:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypingError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 124\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRebinning der Daten mit Faktor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mREBIN_FACTOR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Numba-optimiert)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m start_rebin = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m rebinned_data = \u001b[43mrebin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_raw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_raw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mREBIN_FACTOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m rebinned_time = t_full[::REBIN_FACTOR] \u001b[38;5;66;03m# Die Zeitpunkte nach dem Rebinning\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRebinning beendet in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_rebin\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Sekunden.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ag/lib/python3.11/site-packages/numba/core/dispatcher.py:424\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    420\u001b[39m         msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e).rstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis error may have been caused \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m         e.patch_message(msg)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtyping\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.UnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[32m    427\u001b[39m     error_rewrite(e, \u001b[33m'\u001b[39m\u001b[33munsupported_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ag/lib/python3.11/site-packages/numba/core/dispatcher.py:365\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[39m\u001b[34m(e, issue_type)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypingError\u001b[39m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<function mean at 0x106c02fc0>) found for signature:\n \n >>> mean(array(float64, 4d, C), axis=Literal[int](3))\n \nThere are 2 candidate implementations:\n\u001b[1m  - Of which 2 did not match due to:\n  Overload in function 'array_mean': File: numba/np/old_arraymath.py: Line 424.\n    With argument(s): '(array(float64, 4d, C), axis=int64)':\u001b[0m\n\u001b[1m   Rejected as the implementation raised a specific error:\n     TypingError: \u001b[1mgot an unexpected keyword argument 'axis'\u001b[0m\u001b[0m\n  raised from /opt/miniconda3/envs/ag/lib/python3.11/site-packages/numba/core/typing/templates.py:791\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<function mean at 0x106c02fc0>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /var/folders/bm/0j4cpchs2qx9r4_5l3k5pd5c0000gn/T/ipykernel_71226/3309363379.py (81)\n\u001b[0m\n\u001b[1m\nFile \"../../../var/folders/bm/0j4cpchs2qx9r4_5l3k5pd5c0000gn/T/ipykernel_71226/3309363379.py\", line 81:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import odeint\n",
    "import sklearn.preprocessing\n",
    "from numba import jit # Importiere Numba für Optimierungen\n",
    "import time # Für Performance-Messung\n",
    "\n",
    "# --- 1. Lorenz System Definition (mit Numba-Optimierung) ---\n",
    "rho = 45.92\n",
    "sigma = 16.0\n",
    "beta = 8.0 / 2.0\n",
    "\n",
    "@jit(nopython=True)\n",
    "def lorenz_equation(state, t):\n",
    "    \"\"\"Die Lorenz-Gleichungen, optimiert mit Numba.\"\"\"\n",
    "    x, y, z = state\n",
    "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z\n",
    "\n",
    "def lorenz(t, init):\n",
    "    \"\"\"Löst das Lorenz-System für gegebene Startwerte und Zeitpunkte.\"\"\"\n",
    "    # odeint ruft die Numba-optimierte lorenz_equation auf\n",
    "    return odeint(lorenz_equation, init, t)\n",
    "\n",
    "# --- 2. Numba-optimierte Helferfunktion für Mischen und Rauschen ---\n",
    "@jit(nopython=True)\n",
    "def _mix_and_noise(data_out, candidates_arr, randoms, mixtures, noise):\n",
    "    \"\"\"Numba-optimierte Logik zum Mischen von Kandidaten und Hinzufügen von Rauschen.\"\"\"\n",
    "    num_samples = data_out.shape[0]\n",
    "    num_mixtures = len(mixtures)\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        current_random = randoms[idx]\n",
    "        selected_candidate_idx = -1\n",
    "        \n",
    "        for mix_idx in range(num_mixtures):\n",
    "            if mix_idx == 0:\n",
    "                if current_random >= 0 and current_random < mixtures[mix_idx]:\n",
    "                    selected_candidate_idx = mix_idx\n",
    "                    break\n",
    "            else:\n",
    "                if current_random >= mixtures[mix_idx-1] and current_random < mixtures[mix_idx]:\n",
    "                    selected_candidate_idx = mix_idx\n",
    "                    break\n",
    "        \n",
    "        if selected_candidate_idx != -1:\n",
    "            noise_array = np.random.normal(loc=0.0, scale=noise, size=data_out[idx].shape)\n",
    "            data_out[idx] = candidates_arr[selected_candidate_idx] + noise_array\n",
    "    return data_out\n",
    "\n",
    "# --- 3. Haupt-Daten-Generierungsfunktion (ruft Numba-Teil auf) ---\n",
    "def generate_data_optimized(t_full, samples, mixtures, inits, noise):\n",
    "    \"\"\"Generiert die Lorenz-Zeitreihendaten, indem sie Numba-optimierte Teile nutzt.\"\"\"\n",
    "    print(f\"Generiere {len(inits)} Lorenz-Kandidaten (Länge: {t_full.shape[0]} Punkte)...\")\n",
    "    candidates_list = []\n",
    "    start_candidates = time.time()\n",
    "    for init_idx, init in enumerate(inits):\n",
    "        print(f\"  Simuliere Kandidat {init_idx + 1}/{len(inits)}...\")\n",
    "        candidates_list.append(lorenz(t_full, init)[:, 0:1])\n",
    "    candidates_arr = np.array(candidates_list)\n",
    "    print(f\"  Kandidaten-Simulation beendet in {time.time() - start_candidates:.2f} Sekunden.\")\n",
    "\n",
    "    print(f\"Mische und füge Rauschen hinzu für {samples} Samples (Numba-optimiert)...\")\n",
    "    data_out = np.zeros((samples, t_full.shape[0], 1), dtype=np.float64)\n",
    "    randoms = np.random.uniform(size=samples)\n",
    "\n",
    "    start_mix_noise = time.time()\n",
    "    data_out = _mix_and_noise(data_out, candidates_arr, randoms, mixtures, noise)\n",
    "    print(f\"  Mischen und Rauschen beendet in {time.time() - start_mix_noise:.2f} Sekunden.\")\n",
    "    \n",
    "    return data_out, None, t_full\n",
    "\n",
    "# --- 4. Numba-optimierte Rebinning-Funktion ---\n",
    "@jit(nopython=True)\n",
    "def rebin(arr, new_shape):\n",
    "    \"\"\"Numba-optimierte Funktion zum Rebinning eines 3D-Arrays.\"\"\"\n",
    "    shape = (new_shape[0], arr.shape[0] // new_shape[0],\n",
    "             new_shape[1], arr.shape[1] // new_shape[1],)\n",
    "    \n",
    "    reshaped_arr = arr.reshape(shape)\n",
    "    \n",
    "    mean_last_axis = np.mean(reshaped_arr, axis=3)\n",
    "    mean_second_axis = np.mean(mean_last_axis, axis=1)\n",
    "    \n",
    "    return mean_second_axis\n",
    "\n",
    "# --- 5. Hauptskript: Parameter und Datengenerierung ---\n",
    "print(\"🚀 Starte Generierung der Lorenz-Zeitreihen mit Numba-Optimierung...\")\n",
    "\n",
    "# Anpassung: Sehr lange Zeitachse für 10.000 Einträge pro Kanal\n",
    "# (10.000 Punkte * Rebinning-Faktor 100 = 1.000.000 Rohpunkte)\n",
    "t_full = np.arange(0.0, 20000.0, 0.02) # Erzeugt 1.000.000 Rohpunkte\n",
    "num_samples = 10 # Anzahl der Kanäle\n",
    "\n",
    "# Initialparameter für Lorenz-Simulationen (unverändert)\n",
    "inits = [\n",
    "    [ 1.0, 1.0001         , 1.0 ],\n",
    "    [ 1.0, 1.000001       , 1.0 ],\n",
    "    [ 1.0, 1.00000001     , 1.0 ],\n",
    "    [ 1.0, 1.0000000001   , 1.0 ],\n",
    "    [ 1.0, 1.000000000001 , 1.0 ],\n",
    "]\n",
    "\n",
    "# Mischungsverhältnisse generieren (unverändert)\n",
    "num_candidates = 5\n",
    "points = 1000 \n",
    "distr = np.clip(np.random.normal(loc=0.5, scale=0.2, size=points), a_min=0, a_max=1)\n",
    "mixtures, edges = np.histogram(distr, bins=num_candidates)\n",
    "mixtures = mixtures / points\n",
    "tmp = 0\n",
    "for i, mixture in enumerate(mixtures):\n",
    "    tmp += mixture\n",
    "    mixtures[i] = tmp\n",
    "mixtures_arr = np.array(mixtures, dtype=np.float64) # Für Numba als NumPy-Array\n",
    "\n",
    "# Daten generieren mit der optimierten Funktion\n",
    "start_total_generation = time.time()\n",
    "data_raw, _, t_generated = generate_data_optimized(t_full, samples=num_samples, mixtures=mixtures_arr, inits=inits, noise=7.2)\n",
    "print(f\"Gesamte Rohdaten-Generierung beendet in {time.time() - start_total_generation:.2f} Sekunden.\")\n",
    "\n",
    "# Rebinning-Faktor anpassen für 10.000 Punkte\n",
    "REBIN_FACTOR = 100 \n",
    "print(f\"\\nRebinning der Daten mit Faktor {REBIN_FACTOR} (Numba-optimiert)...\")\n",
    "start_rebin = time.time()\n",
    "rebinned_data = rebin(data_raw[:, :, 0], (data_raw.shape[0], data_raw.shape[1] // REBIN_FACTOR))\n",
    "rebinned_time = t_full[::REBIN_FACTOR] # Die Zeitpunkte nach dem Rebinning\n",
    "print(f\"Rebinning beendet in {time.time() - start_rebin:.2f} Sekunden.\")\n",
    "\n",
    "# Skalierung der Daten\n",
    "print(\"Skaliere die Daten...\")\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-10, 10))\n",
    "scaler.fit(rebinned_data)\n",
    "rebinned_data_scaled = scaler.transform(rebinned_data)\n",
    "\n",
    "print(f\"Shape der skalierten, rebinned Daten: {rebinned_data_scaled.shape} (Soll: {num_samples}x{t_full.shape[0] // REBIN_FACTOR})\")\n",
    "print(f\"Anzahl der Zeitpunkte pro Serie (nach Rebinning): {rebinned_data_scaled.shape[1]}\")\n",
    "\n",
    "# --- 6. Transformation ins Long-Format ---\n",
    "long_format_data = []\n",
    "# Generische Start-Unix-Zeit in Nanosekunden (z.B. 1. Januar 2020)\n",
    "start_unix_ns = pd.Timestamp('2020-01-01 00:00:00 UTC').value\n",
    "\n",
    "# Zeitabstand in Nanosekunden (entspricht dem Abstand in rebinned_time)\n",
    "time_step_ns = (rebinned_time[1] - rebinned_time[0]) * 1_000_000_000 \n",
    "\n",
    "print(\"\\n📈 Konvertiere Daten ins Long-Format...\")\n",
    "start_long_format = time.time()\n",
    "for i in range(num_samples):\n",
    "    current_series_times = np.array([start_unix_ns + j * time_step_ns for j in range(rebinned_data_scaled.shape[1])])\n",
    "    series_data = rebinned_data_scaled[i]\n",
    "\n",
    "    df_temp = pd.DataFrame({\n",
    "        'date': current_series_times, \n",
    "        'data': series_data,          \n",
    "        'cols': f'Channel_{i}'        \n",
    "    })\n",
    "    long_format_data.append(df_temp)\n",
    "\n",
    "df_time_series_long = pd.concat(long_format_data, ignore_index=True)\n",
    "print(f\"Konvertierung ins Long-Format beendet in {time.time() - start_long_format:.2f} Sekunden.\")\n",
    "\n",
    "print(\"\\n🎉 Lorenz-Zeitreihen im Long-Format erfolgreich erstellt!\")\n",
    "print(\"\\n📦 Erste 5 Zeilen des Long-Format DataFrames:\")\n",
    "print(df_time_series_long.head())\n",
    "\n",
    "print(\"\\n📊 DataFrame Info:\")\n",
    "df_time_series_long.info()\n",
    "\n",
    "print(f\"\\n📏 Gesamt-DataFrame Shape: {df_time_series_long.shape}\")\n",
    "\n",
    "# Optional: Speichern als CSV\n",
    "# print(\"\\nSpeichere DataFrame als CSV (dies kann etwas dauern)...\")\n",
    "# start_save = time.time()\n",
    "# df_time_series_long.to_csv(\"lorenz_time_series_long_format_10k_points_numba.csv\", index=False)\n",
    "# print(f\"Speichern beendet in {time.time() - start_save:.2f} Sekunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d3f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starte Generierung der Lorenz-Zeitreihen mit Numba-Optimierung...\n",
      "Generiere 5 Lorenz-Kandidaten (Länge: 1000000 Punkte)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating Lorenz Candidates: 100%|██████████| 5/5 [00:25<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Kandidaten-Simulation beendet in 25.23 Sekunden.\n",
      "Mische und füge Rauschen hinzu für 10 Samples (Numba-optimiert)...\n",
      "  Mischen und Rauschen beendet in 1.80 Sekunden.\n",
      "Gesamte Rohdaten-Generierung beendet in 27.04 Sekunden.\n",
      "\n",
      "Rebinning der Daten mit Faktor 100 (Numba-optimiert)...\n",
      "Rebinning beendet in 0.13 Sekunden.\n",
      "Skaliere die Daten...\n",
      "Shape der skalierten, rebinned Daten: (10, 10000) (Soll: 10x10000)\n",
      "Anzahl der Zeitpunkte pro Serie (nach Rebinning): 10000\n",
      "\n",
      "📈 Konvertiere Daten ins Long-Format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to Long Format: 100%|██████████| 10/10 [00:00<00:00, 580.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konvertierung ins Long-Format beendet in 0.02 Sekunden.\n",
      "\n",
      "🎉 Lorenz-Zeitreihen im Long-Format erfolgreich erstellt!\n",
      "\n",
      "📦 Erste 5 Zeilen des Long-Format DataFrames:\n",
      "           date      data       cols\n",
      "0  1.577837e+18 -3.502282  Channel_0\n",
      "1  1.577837e+18 -8.361674  Channel_0\n",
      "2  1.577837e+18 -4.336743  Channel_0\n",
      "3  1.577837e+18 -8.960544  Channel_0\n",
      "4  1.577837e+18  1.055208  Channel_0\n",
      "\n",
      "📊 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    100000 non-null  float64\n",
      " 1   data    100000 non-null  float64\n",
      " 2   cols    100000 non-null  object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "\n",
      "📏 Gesamt-DataFrame Shape: (100000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import odeint\n",
    "import sklearn.preprocessing\n",
    "from numba import jit # Importiere Numba für Optimierungen\n",
    "import time # Für Performance-Messung\n",
    "from tqdm import tqdm # Importiere tqdm für Fortschrittsbalken\n",
    "\n",
    "# --- 1. Lorenz System Definition (mit Numba-Optimierung) ---\n",
    "rho = 45.92\n",
    "sigma = 16.0\n",
    "beta = 8.0 / 2.0\n",
    "\n",
    "@jit(nopython=True)\n",
    "def lorenz_equation(state, t):\n",
    "    \"\"\"Die Lorenz-Gleichungen, optimiert mit Numba.\"\"\"\n",
    "    x, y, z = state\n",
    "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z\n",
    "\n",
    "def lorenz(t, init):\n",
    "    \"\"\"Löst das Lorenz-System für gegebene Startwerte und Zeitpunkte.\"\"\"\n",
    "    # odeint ruft die Numba-optimierte lorenz_equation auf\n",
    "    return odeint(lorenz_equation, init, t)\n",
    "\n",
    "# --- 2. Numba-optimierte Helferfunktion für Mischen und Rauschen ---\n",
    "@jit(nopython=True)\n",
    "def _mix_and_noise(data_out, candidates_arr, randoms, mixtures, noise):\n",
    "    \"\"\"Numba-optimierte Logik zum Mischen von Kandidaten und Hinzufügen von Rauschen.\"\"\"\n",
    "    num_samples = data_out.shape[0]\n",
    "    num_mixtures = len(mixtures)\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        current_random = randoms[idx]\n",
    "        selected_candidate_idx = -1\n",
    "        \n",
    "        for mix_idx in range(num_mixtures):\n",
    "            if mix_idx == 0:\n",
    "                if current_random >= 0 and current_random < mixtures[mix_idx]:\n",
    "                    selected_candidate_idx = mix_idx\n",
    "                    break\n",
    "            else:\n",
    "                if current_random >= mixtures[mix_idx-1] and current_random < mixtures[mix_idx]:\n",
    "                    selected_candidate_idx = mix_idx\n",
    "                    break\n",
    "        \n",
    "        if selected_candidate_idx != -1:\n",
    "            noise_array = np.random.normal(loc=0.0, scale=noise, size=data_out[idx].shape)\n",
    "            data_out[idx] = candidates_arr[selected_candidate_idx] + noise_array\n",
    "    return data_out\n",
    "\n",
    "# --- 3. Haupt-Daten-Generierungsfunktion (ruft Numba-Teil auf) ---\n",
    "def generate_data_optimized(t_full, samples, mixtures, inits, noise):\n",
    "    \"\"\"Generiert die Lorenz-Zeitreihendaten, indem sie Numba-optimierte Teile nutzt.\"\"\"\n",
    "    print(f\"Generiere {len(inits)} Lorenz-Kandidaten (Länge: {t_full.shape[0]} Punkte)...\")\n",
    "    candidates_list = []\n",
    "    start_candidates = time.time()\n",
    "    # tqdm für die Schleife über die initialen Bedingungen\n",
    "    for init_idx, init in enumerate(tqdm(inits, desc=\"Simulating Lorenz Candidates\")):\n",
    "        candidates_list.append(lorenz(t_full, init)[:, 0:1])\n",
    "    candidates_arr = np.array(candidates_list)\n",
    "    print(f\"  Kandidaten-Simulation beendet in {time.time() - start_candidates:.2f} Sekunden.\")\n",
    "\n",
    "    print(f\"Mische und füge Rauschen hinzu für {samples} Samples (Numba-optimiert)...\")\n",
    "    data_out = np.zeros((samples, t_full.shape[0], 1), dtype=np.float64)\n",
    "    randoms = np.random.uniform(size=samples)\n",
    "\n",
    "    start_mix_noise = time.time()\n",
    "    # Keine tqdm hier, da _mix_and_noise ein einzelner schneller Numba-Aufruf ist\n",
    "    data_out = _mix_and_noise(data_out, candidates_arr, randoms, mixtures, noise)\n",
    "    print(f\"  Mischen und Rauschen beendet in {time.time() - start_mix_noise:.2f} Sekunden.\")\n",
    "    \n",
    "    return data_out, None, t_full\n",
    "\n",
    "# --- 4. Numba-optimierte Rebinning-Funktion (FEHLER BEHOBEN) ---\n",
    "@jit(nopython=True)\n",
    "def rebin(arr, new_shape):\n",
    "    \"\"\"\n",
    "    Numba-optimierte Funktion zum Rebinning eines 2D-Arrays (arr[series, time]).\n",
    "    Verwendet explizite Schleifen für bessere Numba-Kompatibilität.\n",
    "    \"\"\"\n",
    "    # arr.shape = (num_series, num_raw_points)\n",
    "    # new_shape = (num_series, num_rebinned_points)\n",
    "\n",
    "    num_series, num_raw_points = arr.shape\n",
    "    _, num_rebinned_points = new_shape\n",
    "\n",
    "    bin_size = num_raw_points // num_rebinned_points \n",
    "\n",
    "    out = np.empty(new_shape, dtype=arr.dtype)\n",
    "\n",
    "    for i in range(num_series): # Iteriere über jede Zeitreihe\n",
    "        for j in range(num_rebinned_points): # Iteriere über jeden neuen rebinned Punkt\n",
    "            # Extrahiere das Segment und berechne dessen Mittelwert\n",
    "            segment_start = j * bin_size\n",
    "            segment_end = (j + 1) * bin_size\n",
    "            out[i, j] = np.mean(arr[i, segment_start:segment_end]) # np.mean auf 1D-Segment\n",
    "            \n",
    "    return out\n",
    "\n",
    "# --- 5. Hauptskript: Parameter und Datengenerierung ---\n",
    "print(\"🚀 Starte Generierung der Lorenz-Zeitreihen mit Numba-Optimierung...\")\n",
    "\n",
    "# Anpassung: Sehr lange Zeitachse für 10.000 Einträge pro Kanal\n",
    "# (10.000 Punkte * Rebinning-Faktor 100 = 1.000.000 Rohpunkte pro Simulation)\n",
    "t_full = np.arange(0.0, 20000.0, 0.02) # Erzeugt 1.000.000 Rohpunkte\n",
    "num_samples = 10 # Anzahl der Kanäle\n",
    "\n",
    "# Initialparameter für Lorenz-Simulationen (unverändert)\n",
    "inits = [\n",
    "    [ 1.0, 1.0001         , 1.0 ],\n",
    "    [ 1.0, 1.000001       , 1.0 ],\n",
    "    [ 1.0, 1.00000001     , 1.0 ],\n",
    "    [ 1.0, 1.0000000001   , 1.0 ],\n",
    "    [ 1.0, 1.000000000001 , 1.0 ],\n",
    "]\n",
    "\n",
    "# Mischungsverhältnisse generieren (unverändert)\n",
    "num_candidates = 5\n",
    "points = 1000 \n",
    "distr = np.clip(np.random.normal(loc=0.5, scale=0.2, size=points), a_min=0, a_max=1)\n",
    "mixtures, edges = np.histogram(distr, bins=num_candidates)\n",
    "mixtures = mixtures / points\n",
    "tmp = 0\n",
    "for i, mixture in enumerate(mixtures):\n",
    "    tmp += mixture\n",
    "    mixtures[i] = tmp\n",
    "mixtures_arr = np.array(mixtures, dtype=np.float64) # Für Numba als NumPy-Array\n",
    "\n",
    "# Daten generieren mit der optimierten Funktion\n",
    "start_total_generation = time.time()\n",
    "data_raw, _, t_generated = generate_data_optimized(t_full, samples=num_samples, mixtures=mixtures_arr, inits=inits, noise=7.2)\n",
    "print(f\"Gesamte Rohdaten-Generierung beendet in {time.time() - start_total_generation:.2f} Sekunden.\")\n",
    "\n",
    "# Rebinning-Faktor anpassen für 10.000 Punkte pro Kanal\n",
    "REBIN_FACTOR = 100 \n",
    "print(f\"\\nRebinning der Daten mit Faktor {REBIN_FACTOR} (Numba-optimiert)...\")\n",
    "start_rebin = time.time()\n",
    "# `data_raw[:, :, 0]` macht es zu einem 2D-Array, wie es `rebin` jetzt erwartet\n",
    "rebinned_data = rebin(data_raw[:, :, 0], (data_raw.shape[0], data_raw.shape[1] // REBIN_FACTOR)) \n",
    "rebinned_time = t_full[::REBIN_FACTOR] # Die Zeitpunkte nach dem Rebinning\n",
    "print(f\"Rebinning beendet in {time.time() - start_rebin:.2f} Sekunden.\")\n",
    "\n",
    "# Skalierung der Daten\n",
    "print(\"Skaliere die Daten...\")\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-10, 10))\n",
    "scaler.fit(rebinned_data)\n",
    "rebinned_data_scaled = scaler.transform(rebinned_data)\n",
    "\n",
    "print(f\"Shape der skalierten, rebinned Daten: {rebinned_data_scaled.shape} (Soll: {num_samples}x{t_full.shape[0] // REBIN_FACTOR})\")\n",
    "print(f\"Anzahl der Zeitpunkte pro Serie (nach Rebinning): {rebinned_data_scaled.shape[1]}\")\n",
    "\n",
    "# --- 6. Transformation ins Long-Format ---\n",
    "long_format_data = []\n",
    "# Generische Start-Unix-Zeit in Nanosekunden (z.B. 1. Januar 2020)\n",
    "start_unix_ns = pd.Timestamp('2020-01-01 00:00:00 UTC').value\n",
    "\n",
    "# Zeitabstand in Nanosekunden (entspricht dem Abstand in rebinned_time)\n",
    "time_step_ns = (rebinned_time[1] - rebinned_time[0]) * 1_000_000_000 \n",
    "\n",
    "print(\"\\n📈 Konvertiere Daten ins Long-Format...\")\n",
    "start_long_format = time.time()\n",
    "# tqdm für die Schleife über die Samples beim Konvertieren\n",
    "for i in tqdm(range(num_samples), desc=\"Converting to Long Format\"): \n",
    "    current_series_times = np.array([start_unix_ns + j * time_step_ns for j in range(rebinned_data_scaled.shape[1])])\n",
    "    series_data = rebinned_data_scaled[i]\n",
    "\n",
    "    df_temp = pd.DataFrame({\n",
    "        'date': current_series_times, \n",
    "        'data': series_data,          \n",
    "        'cols': f'Channel_{i}'        \n",
    "    })\n",
    "    long_format_data.append(df_temp)\n",
    "\n",
    "df_time_series_long = pd.concat(long_format_data, ignore_index=True)\n",
    "print(f\"Konvertierung ins Long-Format beendet in {time.time() - start_long_format:.2f} Sekunden.\")\n",
    "\n",
    "print(\"\\n🎉 Lorenz-Zeitreihen im Long-Format erfolgreich erstellt!\")\n",
    "print(\"\\n📦 Erste 5 Zeilen des Long-Format DataFrames:\")\n",
    "print(df_time_series_long.head())\n",
    "\n",
    "print(\"\\n📊 DataFrame Info:\")\n",
    "df_time_series_long.info()\n",
    "\n",
    "print(f\"\\n📏 Gesamt-DataFrame Shape: {df_time_series_long.shape}\")\n",
    "\n",
    "# Optional: Speichern als CSV\n",
    "# print(\"\\nSpeichere DataFrame als CSV (dies kann etwas dauern)...\")\n",
    "# start_save = time.time()\n",
    "# df_time_series_long.to_csv(\"lorenz_time_series_long_format_10k_points_numba_fixed.csv\", index=False)\n",
    "# print(f\"Speichern beendet in {time.time() - start_save:.2f} Sekunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c5f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series_long.to_csv(\"lorenz.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845667a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
